<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI and the Uneven Scales of Progress: Inequalities in Development</title>
    <link rel="stylesheet" href="../css/custom.min.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>AI and the Uneven Scales of Progress: Inequalities in Development</h1>
        </header>

        <section id="introduction">
            <!-- <h2>Introduction</h2> -->
            <p>
                Artificial intelligence (AI) has been widely heralded as the next great technological revolution, promising efficiency, economic growth, and scientific breakthroughs. Governments and corporations are investing billions into AI research, with the assumption that these advancements will benefit society as a whole. However, like previous technological revolutions, the rise of AI is deeply unequal - both in terms of who develops it and who benefits from it.<br>The AI industry is overwhelmingly concentrated in a few wealthy countries, while lower-income nations remain largely excluded from its economic gains. Additionally, AI systems often exacerbate existing social inequalities by reproducing biases in decision-making processes, reinforcing systemic discrimination, and further concentrating power in the hands of a small elite. Furthermore, AI's environmental footprint disproportionately affects marginalized communities while its primary beneficiaries continue unchecked expansion. This essay examines the uneven distribution of AI development, the exploitation embedded within AI's global supply chains, and how AI-driven automation and its environmental costs disproportionately impact already marginalized communities.
            </p>
        </section>

        <section id="global-divide">
            <h2>The Global Divide in AI Development</h2>
            <p>
                The AI sector is dominated by a small number of companies and countries. The United States and China lead the field, with firms like Google, OpenAI, Microsoft, Baidu, and Tencent controlling the majority of cutting-edge AI models and research output<sup>1</sup>. Meanwhile, Europe struggles to keep pace, and lower-income countries contribute very little to AI innovation despite having vast populations and growing digital economies<sup>2</sup>.<br>This technological divide is partly due to access to computational resources. Training state-of-the-art AI models requires immense computing power, which only well-funded organizations can afford. For example, OpenAI's GPT-4 was trained using thousands of high-performance GPUs, consuming vast amounts of energy<sup>3</sup>. The financial and infrastructural barriers to AI development make it nearly impossible for smaller nations or independent researchers to compete, consolidating AI power in wealthy institutions.<br>Furthermore, the legal and political frameworks surrounding AI are set by these dominant players, often to their advantage. While some nations attempt to regulate AI for fairness and accountability, companies with vast financial resources can shape AI policies to favor their business models rather than broader societal needs<sup>4</sup>.
            </p>
        </section>

        <section id="hidden-workforce">
            <h2>AI's Hidden Workforce: Exploitation in the Data Economy</h2>
            <p>
                While AI is often framed as a cutting-edge field driven by highly skilled researchers, much of its foundation relies on hidden labor, often performed under precarious conditions. AI models require vast amounts of labeled data, which is primarily annotated by low-wage workers in developing countries.<br>Platforms like Amazon Mechanical Turk, Appen, and Sama employ thousands of people in Kenya, the Philippines, and India to label images, transcribe speech, and moderate content. These tasks are essential for training AI models, yet the workers performing them receive poverty-level wages with no job security<sup>5</sup>. For example, Facebook's AI content moderation team in Kenya was found to be paid as little as $1.50 per hour, despite being exposed to disturbing content daily<sup>1</sup>.<br>Beyond annotation, AI also relies on the extraction of raw materials for computational power. Data centers and AI hardware require rare earth minerals like lithium and cobalt, often mined under exploitative conditions in the Democratic Republic of Congo and other resource-rich yet economically disadvantaged regions<sup>6</sup>. This mirrors historical colonial patterns, where low-income countries serve as raw material providers for industrialized economies.<br>Thus, while AI is marketed as a futuristic and sophisticated technology, its global supply chain reflects age-old economic inequalities: wealthy nations control research and profits, while low-income nations provide the cheap labor and materials that sustain the industry.
            </p>
        </section>

        <section id="environmental-costs">
            <h2>The Environmental Costs of AI: Who Pays the Price?</h2>
            <p>Artificial intelligence is often depicted as an intangible force of progress, but its infrastructure relies on vast amounts of energy, raw materials, and water, with severe environmental consequences. These costs are outsourced to marginalized communities, while the benefits of AI remain concentrated in wealthy nations and corporations.</p>
            
            <h3>Energy Consumption and Carbon Emissions</h3>
            <p>Training large AI models requires massive amounts of computational power. The energy demand of data centers running AI systems rivals that of small nations, and much of this electricity comes from non-renewable sources such as coal and natural gas<sup>3</sup>. A single large AI model can generate as much COâ‚‚ as five cars over their entire lifetime<sup>7</sup>. Despite claims of sustainability, many companies rely on energy offset schemes rather than direct reductions in emissions<sup>6</sup>.</p>
            
            <h3>The Mining of Rare Earth Metals</h3>
            <p>AI models depend on GPUs and semiconductors that require lithium, cobalt, and nickel. These materials are primarily mined in the Democratic Republic of Congo, Chile, and Indonesia, where operations destroy ecosystems and exploit workers<sup>6</sup>.</p>
            
            <ul>
                <li>Lithium mining has caused severe droughts in Chile and Argentina, as it consumes vast amounts of freshwater<sup>8</sup>.</li>
                <li>Cobalt mining in the DRC is notorious for child labor and toxic exposure, benefiting multinational corporations while local communities remain impoverished<sup>9</sup>.</li>
            </ul>
            
            <p>The communities affected by these operations receive none of AI's economic benefits. Instead, they bear the brunt of water shortages, land destruction, and political instability caused by resource extraction<sup>6</sup>.</p>
            
            <h3>Who Bears the Environmental Burden?</h3>
            <p>The environmental consequences of AI fall disproportionately on the Global South, while the profits remain in Silicon Valley, Beijing, and other tech hubs.</p>
            
            <ul>
                <li>AI-driven carbon emissions accelerate climate change, which disproportionately affects coastal and equatorial nations.</li>
                <li>E-waste disposal from outdated AI hardware is exported to Africa and Southeast Asia, where it is dumped in toxic landfills<sup>6</sup>.</li>
                <li>Resource conflicts over cobalt and lithium fuel violence and political instability, worsening conditions in already struggling regions<sup>9</sup>.</li>
            </ul>
            
            <p>Meanwhile, major AI firms face no direct consequences for their environmental impact. Instead, they continue expanding operations under the guise of technological progress, disregarding sustainability concerns.</p>
        </section>

        <section id="bias-discrimination">
            <h2>Bias and Discrimination: AI as a Reinforcer of Social Inequality</h2>
            <p>
                AI systems do not just reflect economic and environmental inequalities - they actively reinforce them. Multiple studies show that AI models frequently discriminate against marginalized communities due to biases in training data<sup>10</sup>.<br>For instance, AI-driven hiring systems have been found to favor male candidates over female applicants<sup>11</sup>. Similarly, facial recognition software has higher error rates for Black and Indigenous individuals, leading to wrongful arrests in policing applications<sup>12</sup>.<br>These biases emerge because AI models learn from historical data shaped by systemic discrimination. Instead of correcting these injustices, AI often amplifies them at scale.
            </p>
        </section>

        <section id="conclusion">
            <h2>Conclusion</h2>
            <p>
                AI is often portrayed as a transformative force that will uplift humanity, but its development is riddled with inequality, exploitation, and environmental destruction. The benefits of AI remain concentrated among tech giants and wealthy nations, while low-income countries and marginalized communities bear its costs. From exploitative labor conditions and biased decision-making to the devastating environmental footprint of AI infrastructure, the so-called progress of artificial intelligence remains deeply unequal and unsustainable.<br>If AI is to serve all of humanity, its development must be restructured to prioritize fairness, sustainability, and equity. Otherwise, AI will not be a tool of progress - it will be an instrument of deepening inequality on a planetary scale.
            </p>
        </section>

        <section id="references">
            <h2>References</h2>
            <ul>
                <li><sup>1</sup> Bender, E. M., et al. (2021). "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" <em>FAccT</em>.</li>
                <li><sup>2</sup> Crawford, K. (2021). <em>Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</em>. Yale University Press.</li>
                <li><sup>3</sup> Patterson, D., et al. (2021). "The Carbon Footprint of AI Model Training", <em>MIT Technology Review</em>.</li>
                <li><sup>4</sup> Zuboff, S. (2019). <em>The Age of Surveillance Capitalism</em>. PublicAffairs.</li>
                <li><sup>5</sup> Tubaro, P., et al. (2020). "The Hidden Labor of AI Data Annotation", <em>New Media & Society</em>.</li>
                <li><sup>6</sup> Hickel, J. (2020). <em>Less is More: How Degrowth Will Save the World</em>. William Heinemann.</li>
                <li><sup>7</sup> Strubell, E., et al. (2019). "Energy and Policy Considerations for Deep Learning in NLP", <em>ACL Conference on Empirical Methods in NLP</em>.</li>
                <li><sup>8</sup> Klein, N. (2022). <em>On Fire: The Burning Case for a Green New Deal</em>. Penguin.</li>
                <li><sup>9</sup> Nkulu, C. B., et al. (2018). "Sustainability Challenges in the Cobalt Mining Sector of the Democratic Republic of the Congo", <em>Nature Sustainability</em>.</li>
                <li><sup>10</sup> Benjamin, R. (2019). <em>Race After Technology: Abolitionist Tools for the New Jim Code</em>. Polity Press.</li>
                <li><sup>11</sup> Raghavan, M., et al. (2020). "Mitigating Bias in Algorithmic Hiring: Evaluating Strategies in Pre-employment Assessments", <em>FAccT</em>.</li>
                <li><sup>12</sup> Buolamwini, J., & Gebru, T. (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification", <em>Conference on Fairness, Accountability, and Transparency</em>.</li>
            </ul>
        </section>        

        <footer>
            <p>
                <strong>Author:</strong> Daniel Netzl<br>
                <strong>Date:</strong> February 2025<br>
                <a href="../index.html" class="btn">Back to Home</a>
            </p>
        </footer>
    </div>
</body>
</html>
